{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QRunFTkb3U4"
      },
      "source": [
        "def reproduceResult():\n",
        "  seed_value= 0\n",
        "\n",
        "  \n",
        "  with tf.device(\"/cpu:0\"):\n",
        "    ...\n",
        "\n",
        "\n",
        "  os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "  np.random.seed(0)\n",
        "  rn.seed(0)\n",
        "\n",
        "\n",
        "  session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, \n",
        "                                          inter_op_parallelism_threads=1)\n",
        "\n",
        "\n",
        "  tf.compat.v1.set_random_seed(seed_value)\n",
        "  sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "  tf.compat.v1.keras.backend.set_session(sess)\n",
        "  tf.compat.v1.keras.backend.clear_session()\n",
        "\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpzA9oKUc9VO",
        "outputId": "7675e9fe-b5cf-418d-b9a3-e4a749e86d4d"
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "  \n",
        "import os \n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random as rn\n",
        "from tensorflow import keras\n",
        "\n",
        "reproduceResult()\n",
        "import tempfile\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "\n",
        "from tensorflow.keras import callbacks\n",
        "\n",
        "from keras_lr_finder import LRFinder\n",
        "from clr_callback import CyclicLR\n",
        "\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "\n",
        "\n",
        "import keras_tuner\n",
        "from kerastuner.tuners import RandomSearch\n",
        "from kerastuner.engine.hyperparameters import HyperParameters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02dllW_vh3yo"
      },
      "source": [
        "def clean_punc(line):\n",
        "  temp = re.sub(r'[?|!|\\'|\"|#]',r'',line)\n",
        "  temp = re.sub(r'[.|,|\"|\")|(|\\|/]',r' ',temp)\n",
        "  return  temp\n",
        "\n",
        "def clean_html(line):\n",
        "  cleanr = re.compile('<.*?>')\n",
        "  cleantext = re.sub(cleanr, ' ', line)\n",
        "  return cleantext\n",
        "\n",
        "def clean_space(line):\n",
        "  return \" \".join(line.split())\n",
        "\n",
        "\n",
        "def clean_char(line):\n",
        "  clean_ch = re.compile('[!@#$%^&*()_+-={}\\[\\];:\\'\\\"\\|<>,.///?`~।]', flags=re.I)\n",
        "  return clean_ch.sub(r'',line)\n",
        "\n",
        "\n",
        "def clean_non_bn_words(line):\n",
        "  clean_en = re.compile('[a-z]', flags=re.I)\n",
        "  clean_en_up = re.compile('[A-Z]', flags=re.I)\n",
        "  clean_digit = re.compile('[0-9]', flags=re.I)\n",
        "  line = clean_en.sub(r'',line)\n",
        "  line = clean_en_up.sub(r'',line)\n",
        "  return clean_digit.sub(r'',line)\n",
        "\n",
        "def clean_emo(line):\n",
        "\n",
        "  result = re.sub('[(\\U0001F600-\\U0001F92F|\\U0001F300-\\U0001F5FF|\\U0001F680-\\U0001F6FF|\\U0001F190-\\U0001F1FF|\\U00002702-\\U000027B0|\\U0001F926-\\U0001FA9F|\\u200d|\\u2640-\\u2642|\\u2600-\\u2B55|\\u23cf|\\u23e9|\\u231a|\\ufe0f)]+','',line)\n",
        "  return result\n",
        "\n",
        "\n",
        "def clean_all(line):\n",
        "  line = clean_html(line)\n",
        "  line = clean_punc(line)\n",
        "  line = clean_char(line)\n",
        "  line = clean_non_bn_words(line)\n",
        "  line = clean_space(line)\n",
        "  return clean_emo(line)\n",
        "\n",
        "\n",
        "def float_to_int(val):\n",
        "  return int(val)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpuVCSYmdEOW",
        "outputId": "63423475-dfdb-49cb-8585-bd0ad46c6637"
      },
      "source": [
        "import re\n",
        "\n",
        "df1 = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Dataset/DeepHateExplainer/train.csv', sep=',', encoding='utf-8')\n",
        "df2 = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Dataset/DeepHateExplainer/test.csv', sep=',', encoding='utf-8')\n",
        "df3 = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Dataset/DeepHateExplainer/validation.csv', sep=',', encoding='utf-8')\n",
        "\n",
        "\n",
        "df1 = df1.dropna()\n",
        "\n",
        "df1['Text'] = df1['text'].apply(clean_all)\n",
        "df2['Text'] = df2['text'].apply(clean_all)\n",
        "df3['Text'] = df3['text'].apply(clean_all)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "del df1['text']\n",
        "del df1['target']\n",
        "del df2['text']\n",
        "del df2['target']\n",
        "del df3['text']\n",
        "del df3['target']\n",
        "\n",
        "\n",
        "frames = [df1, df2, df3]\n",
        "\n",
        "temp = pd.concat(frames)\n",
        "\n",
        "print(temp)\n",
        "\n",
        "temp = temp.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "print(temp)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            label                                               Text\n",
            "0        Personal          ৭৫ হামলার আসামী কে এই গডফাদার কালা মন্দির\n",
            "1       Political  রাজাকারদের মন্ত্রী বানানোর দায়ে তার আরও কঠিন ...\n",
            "2    Geopolitical  বৃটিশ নাগরিকদের বাংলাদেশ ভ্রমনে সতর্কতা জারী ২...\n",
            "3       Political  বলদ নয়াদিগন্ত কালকে রিপোর্ট করলো হিলারী শপথ ন...\n",
            "4    Geopolitical  অসভ্য বর্বর বেহায়া ভোট ডাকাত সকল প্রকার খারাপ...\n",
            "..            ...                                                ...\n",
            "995  Geopolitical            আমরা লুটে পুটে খাই তাই আনন্দের সীমা নাই\n",
            "996      Personal  সব মিমারদের চরিত্র খারাপ তাতে আমার বাল ছিড়া গেছে\n",
            "997      Personal  এই ম্যাইয়ারে হেমায়েতপুর থেইকা খোলা অবস্থায় ...\n",
            "998      Personal  অভিজিৎ রায় হত্যাকান্ড খুনিরা দিব্যি চলে গেল প...\n",
            "999  Geopolitical      পুরো আরবরা কেন পরাজিত আরবদের ইতিহাস জানতে হবে\n",
            "\n",
            "[8087 rows x 2 columns]\n",
            "             label                                               Text\n",
            "0     Geopolitical  রোহিঙ্গাদের ওপর মরিচের গুড়া ও গ্রেনেড ছুড়ছে ...\n",
            "1         Personal               খানকির পোলা তোরে সবাই জুতা পেটা করবে\n",
            "2         Personal  এ গাভীটা নিশ্চয় কোন এমপি মন্ত্রীর ও প্রশাসনের...\n",
            "3     Geopolitical  স্টক এক্সচেঞ্জে হামলার পেছনে ভারত রয়েছে ইমরান...\n",
            "4        Political       এইমাত্র যুবলীগের নেতাকে বেধড়ক পেটালো বিএনপি\n",
            "...            ...                                                ...\n",
            "8082  Geopolitical  শালারা গাজা মনে হয় একটু বেশি খাইছে আগে ভারতী ...\n",
            "8083     Religious      ইহুদীদের পণ্য বর্জনের মাধ্যমে জিহাদে শরিক হোন\n",
            "8084  Geopolitical  আসলো এ কি কলিকাল দেশের প্রধানমন্ত্রীর মুখে পতি...\n",
            "8085     Political  নেতাজি সুভাষ বলতেন তোমরা আমাকে রক্ত দাও আমি তো...\n",
            "8086      Personal   যারা তাহেরী বিরুদ্ধে ভিডিও বানাও তারা একবার দেখো\n",
            "\n",
            "[8087 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbp9q9-fl7lN",
        "outputId": "58593996-8af9-44d0-b5c6-eca901b1eee7"
      },
      "source": [
        "temp.label.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Personal        3513\n",
              "Geopolitical    2364\n",
              "Religious       1211\n",
              "Political        999\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gueC2yo9fIln"
      },
      "source": [
        "train, test = train_test_split(temp, test_size=0.2, stratify = temp['label'], random_state = 42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drbtAtbGmH8H",
        "outputId": "9f2edf10-5a91-4e73-96a5-0db9864e4a06"
      },
      "source": [
        "train.label.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Personal        2810\n",
              "Geopolitical    1891\n",
              "Religious        969\n",
              "Political        799\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1xywr8hlEW9",
        "outputId": "eb5d2d38-eb55-4f8e-ea4b-518ccf5a4fec"
      },
      "source": [
        "num_classes = 4\n",
        "embed_num_dims = 300\n",
        "max_seq_len = 50\n",
        "\n",
        "\n",
        "\n",
        "x_train = train['Text']\n",
        "x_test = test['Text']\n",
        "\n",
        "y_train = train['label']\n",
        "y_test = test['label']\n",
        "\n",
        "texts_train = x_train\n",
        "texts_test = x_test\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train['Text'])\n",
        "tokenizer.fit_on_texts(test['Text'])\n",
        "\n",
        "\n",
        "sequence_train = tokenizer.texts_to_sequences(texts_train)\n",
        "sequence_test = tokenizer.texts_to_sequences(texts_test)\n",
        "\n",
        "index_of_words = tokenizer.word_index\n",
        "\n",
        "vocab_size = len(index_of_words) + 1\n",
        "\n",
        "print('Number of unique words: {}'.format(len(index_of_words)))\n",
        "\n",
        "X_train_pad = pad_sequences(sequence_train, maxlen = max_seq_len, padding='post' )\n",
        "X_test_pad = pad_sequences(sequence_test, maxlen = max_seq_len,  padding='post')\n",
        "\n",
        "print(X_train_pad)\n",
        "\n",
        "\n",
        "encoding = {\n",
        "    'Personal': 0,\n",
        "    'Geopolitical': 1,\n",
        "    'Religious': 2,\n",
        "    'Political': 3,\n",
        "    }\n",
        "\n",
        "y_train = [encoding[x] for x in train['label']]\n",
        "y_test = [encoding[x] for x in test['label']]\n",
        "\n",
        "\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "def create_embedding_matrix(word_index, embedding_dim):\n",
        "    vocab_size = len(word_index) + 1  # Adding again 1 because of reserved 0 index\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "    with open('/content/drive/MyDrive/Colab Notebooks/Dataset/cc.bn.300.vec') as f:\n",
        "        for line in f:\n",
        "            word, *vector = line.split()\n",
        "            if word in word_index:\n",
        "                idx = word_index[word] \n",
        "                embedding_matrix[idx] = np.array(\n",
        "                    vector, dtype=np.float32)[:embedding_dim]\n",
        "    return embedding_matrix\n",
        "\n",
        "\n",
        "embedd_matrix = create_embedding_matrix(index_of_words, embed_num_dims)\n",
        "print(embedd_matrix.shape)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique words: 19282\n",
            "[[9068 9069  302 ...    0    0    0]\n",
            " [ 137 1248 2878 ...    0    0    0]\n",
            " [ 311 1936 1249 ...    0    0    0]\n",
            " ...\n",
            " [   3 5577  108 ...    0    0    0]\n",
            " [ 196   27   46 ...    0    0    0]\n",
            " [8857 2155 5391 ...    0    0    0]]\n",
            "(19283, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsG8oSJfyI9O",
        "outputId": "85c90e62-b9dc-49db-96db-7e5e54cb0f4f"
      },
      "source": [
        "from tensorflow.keras import regularizers\n",
        "import time\n",
        "LOG_DIR = f\"{int(time.time())}\"\n",
        "seed_value= 0\n",
        "\n",
        "\n",
        "\n",
        "def build_model(hp):\n",
        "  \n",
        "  reproduceResult()\n",
        "\n",
        "  print('Ya it comes here')\n",
        "  unit_attention = hp.Int(\"attention_unit\",min_value =32, max_value = 128, step = 16)\n",
        "  fake_val = hp.Int(\"cnn_1_unit\",min_value =16, max_value = 96, step = 16)\n",
        "  cnn_1_unit = hp.Int(\"cnn_1_unit\",min_value =16, max_value = 96, step = 16)\n",
        "  cnn_1_dropout = hp.Float(\"cnn_1_dropout\",min_value = 0.1,max_value = 0.3,step = 0.1)\n",
        "\n",
        "  lstm_unit = hp.Int(\"lstm_unit\",min_value =64, max_value = 256, step = 32)\n",
        "  lstm_dropout = hp.Float(\"lstm_dropout\",min_value = 0.1,max_value = 0.5,step = 0.1)\n",
        "  cnn_2_unit = hp.Int(\"cnn_2_unit\",min_value =64, max_value = 256, step = 32)\n",
        "  cnn_2_dropout = hp.Float(\"cnn_2_dropout\",min_value = 0.1,max_value = 0.5,step = 0.1)\n",
        "\n",
        "\n",
        "\n",
        "  seq_input = keras.layers.Input(shape=(max_seq_len,))\n",
        "\n",
        "  embedded = keras.layers.Embedding(vocab_size,\n",
        "                          embed_num_dims,\n",
        "                          input_length = max_seq_len,\n",
        "                          weights = [embedd_matrix])(seq_input)\n",
        "\n",
        "  cnn = keras.layers.Conv1D(cnn_1_unit,3,kernel_regularizer=regularizers.l2(1e-4),\n",
        "                            bias_regularizer=regularizers.l2(1e-2),\n",
        "                            activity_regularizer=regularizers.l2(1e-4))(embedded)\n",
        "  cnn = keras.layers.Activation(activation='relu')(cnn)\n",
        "  cnn = keras.layers.BatchNormalization()(cnn)\n",
        "  cnn = keras.layers.Dropout(cnn_1_dropout,seed=seed_value)(cnn)\n",
        "\n",
        "  attention_vec = keras.layers.TimeDistributed(keras.layers.Dense(unit_attention))(cnn)\n",
        "  attention_vec = keras.layers.Reshape((48,unit_attention))(attention_vec)\n",
        "  attention_vec = keras.layers.Activation('relu', name = 'cnn_attention_vec')(attention_vec)\n",
        "  attention_output = keras.layers.Dot(axes = 1)([cnn, attention_vec])\n",
        "\n",
        "\n",
        "  lstm = keras.layers.Bidirectional(keras.layers.LSTM(lstm_unit, recurrent_regularizer=regularizers.l2(1e-4),\n",
        "                                                      return_sequences=True,kernel_regularizer=regularizers.l2(1e-4),\n",
        "                                                      bias_regularizer=regularizers.l2(1e-2),\n",
        "                                                      activity_regularizer=regularizers.l2(1e-4),input_shape =(48,)))(attention_output)\n",
        "\n",
        "  lstm = keras.layers.Activation(activation='relu')(lstm)\n",
        "  lstm = keras.layers.BatchNormalization()(lstm)\n",
        "  lstm = keras.layers.Dropout(lstm_dropout,seed=seed_value)(lstm)\n",
        "  \n",
        "  \n",
        "\n",
        "  cnn_2 = keras.layers.Conv1D(cnn_2_unit,3,kernel_regularizer=regularizers.l2(1e-4),\n",
        "                            bias_regularizer=regularizers.l2(1e-2),\n",
        "                            activity_regularizer=regularizers.l2(1e-4))(lstm)\n",
        "  cnn_2 = keras.layers.Activation(activation='relu')(cnn_2)\n",
        "  cnn_2 = keras.layers.BatchNormalization()(cnn_2)\n",
        "  cnn_2 = keras.layers.Dropout(cnn_2_dropout,seed=seed_value)(cnn_2)\n",
        "\n",
        "  max_pooling = keras.layers.GlobalMaxPooling1D()(cnn_2)\n",
        "  output = keras.layers.Dense(num_classes, activation='softmax')(max_pooling)\n",
        "\n",
        "  model = keras.Model(inputs = [seq_input], outputs = output)\n",
        "  model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "stop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
        "                              patience=4,\n",
        "                              restore_best_weights=True,\n",
        "                              verbose=0, mode='max')\n",
        "\n",
        "\n",
        "# clr_step_size = int((len(X_train_pad)/16))\n",
        "# base_lr = 2e-5\n",
        "# max_lr = 1e-3\n",
        "# mode = 'exp_range'\n",
        "\n",
        "\n",
        "# clr = CyclicLR(base_lr = max_lr, max_lr = base_lr, step_size = clr_step_size, mode = mode)\n",
        "\n",
        "\n",
        "\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective = keras_tuner.Objective('val_accuracy', direction=\"max\"),\n",
        "    max_trials = 50,\n",
        "    executions_per_trial = 1,\n",
        "    directory = LOG_DIR\n",
        "    )\n",
        "  \n",
        "tuner.search(x=X_train_pad,y = y_train,epochs = 20, batch_size = 50,callbacks = [stop], \n",
        "             validation_data = (X_test_pad,y_test))\n",
        "\n",
        "\n",
        "tuner.results_summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 28 Complete [00h 06m 26s]\n",
            "val_accuracy: 0.8114956617355347\n",
            "\n",
            "Best val_accuracy So Far: 0.8355994820594788\n",
            "Total elapsed time: 05h 01m 31s\n",
            "\n",
            "Search: Running Trial #29\n",
            "\n",
            "Hyperparameter    |Value             |Best Value So Far \n",
            "attention_unit    |48                |48                \n",
            "cnn_1_unit        |32                |48                \n",
            "cnn_1_dropout     |0.2               |0.2               \n",
            "lstm_unit         |96                |160               \n",
            "lstm_dropout      |0.3               |0.1               \n",
            "cnn_2_unit        |224               |224               \n",
            "cnn_2_dropout     |0.1               |0.5               \n",
            "\n",
            "Ya it comes here\n",
            "Epoch 1/20\n",
            "120/130 [==========================>...] - ETA: 1s - loss: 3.1721 - accuracy: 0.4070"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnLJt2X1yK7X"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}