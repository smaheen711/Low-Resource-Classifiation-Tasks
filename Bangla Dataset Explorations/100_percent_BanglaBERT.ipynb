{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tcGlbspToyg"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyfdEsMlT-2Q"
      },
      "source": [
        "temp = pd.read_excel('/content/drive/My Drive/Colab Notebooks/Dataset/final_dataset.xlsx')\n",
        "\n",
        "del temp['Unnamed: 0']\n",
        "temp['text'] = temp['Text']\n",
        "del temp['Text']\n",
        "temp['label'] = temp['Emotion']\n",
        "del temp['Emotion']\n",
        "\n",
        "# text = pd.read_excel('/content/drive/My Drive/Colab Notebooks/Dataset/50_words_test.xlsx')\n",
        "# train = train.append(text)\n",
        "# train = train.sample(frac=1).reset_index(drop=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78cq9ovGWAoI"
      },
      "source": [
        "train_text, temp_text, train_labels, temp_labels = train_test_split(temp['text'], temp['label'], \n",
        "                                                                    random_state=42, \n",
        "                                                                    test_size=0.3, \n",
        "                                                                    stratify=temp['label'])\n",
        "\n",
        "\n",
        "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
        "                                                                random_state=42, \n",
        "                                                                test_size=0.5, \n",
        "                                                                stratify=temp_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57WxcAvBps_Z",
        "outputId": "f1c26ba8-c954-4637-d56b-2064c484ca8d"
      },
      "source": [
        "test_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9584        happy\n",
              "20542         sad\n",
              "22563         sad\n",
              "20323    surprise\n",
              "330          fear\n",
              "           ...   \n",
              "8737         fear\n",
              "656         happy\n",
              "1805         fear\n",
              "13483       angry\n",
              "3438         fear\n",
              "Name: label, Length: 5400, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEXqA_9xWTAv",
        "outputId": "45880a62-0862-40eb-cf35-b8b88e2cef74"
      },
      "source": [
        "# bert = AutoModel.from_pretrained('/content/drive/My Drive/Colab Notebooks/Dataset/bangla-bert-base')\n",
        "bert = AutoModel.from_pretrained(\"sagorsarker/bangla-bert-base\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"sagorsarker/bangla-bert-base\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at sagorsarker/bangla-bert-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "7dJchIN2jzut",
        "outputId": "47422331-6cc5-46c7-c843-3f069896ff2e"
      },
      "source": [
        "seq_len = [len(i.split()) for i in train_text]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2156810790>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6XgbhHHnTtl"
      },
      "source": [
        "max_seq_len = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoLqDE0inkfd",
        "outputId": "427d8965-c131-403a-ec2f-3587b427cf4b"
      },
      "source": [
        "# tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2204: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7B_QRxHozIO"
      },
      "source": [
        "encoding = {\n",
        "    'happy': 0,\n",
        "    'angry': 1,\n",
        "    'sad': 2,\n",
        "    'disgust': 3,\n",
        "    'surprise': 4,\n",
        "    'fear': 5\n",
        "}\n",
        "\n",
        "train_labels =[encoding[x] for x in train_labels] \n",
        "test_labels = [encoding[x] for x in test_labels]\n",
        "val_labels = [encoding[x] for x in val_labels]\n",
        "# test_labels = [encoding[x] for x in train['Emotion']]\n",
        "# val_labels = [encoding[x] for x in train['Emotion']] \n",
        "# y_train = [encoding[x] for x in train['Emotion']]\n",
        "# y_test = [encoding[x] for x in train['Emotion']]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGaST4B1nny0"
      },
      "source": [
        "# for train set\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels)\n",
        "\n",
        "# for validation set\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(val_labels)\n",
        "\n",
        "# for test set\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nI264VVopMx"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#define a batch size\n",
        "batch_size = 32\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzRFTEOAprTE"
      },
      "source": [
        "# for param in bert.parameters():\n",
        "#     param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atj_Jmq3puGE"
      },
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, bert):\n",
        "      \n",
        "      super(BERT_Arch, self).__init__()\n",
        "\n",
        "      self.bert = bert \n",
        "      \n",
        "      # dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "      \n",
        "      # relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "      \n",
        "      # dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,6)\n",
        "\n",
        "      #softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model  \n",
        "      _, cls_hs = self.bert(sent_id, attention_mask=mask,return_dict=False)\n",
        "      \n",
        "      x = self.fc1(cls_hs)\n",
        "\n",
        "      x = self.relu(x)\n",
        "\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      # output layer\n",
        "      x = self.fc2(x)\n",
        "      \n",
        "      # apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEC_9chYpxbt"
      },
      "source": [
        "device = torch.device(\"cuda\")\n",
        "\n",
        "model = BERT_Arch(bert)\n",
        "\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9JIdILSp8Q7"
      },
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr = 3e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmRY8MueqAA7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a2d91f0-c2f6-48a1-96c3-55dce57e6784"
      },
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#compute the class weights\n",
        "class_wts = compute_class_weight('balanced', np.unique(train_labels), train_labels)\n",
        "\n",
        "print(class_wts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGiINX7rqCer"
      },
      "source": [
        "# convert class weights to tensor\n",
        "weights= torch.tensor(class_wts,dtype=torch.float)\n",
        "weights = weights.to(device)\n",
        "\n",
        "# loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights) \n",
        "\n",
        "# number of training epochs\n",
        "epochs = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKb6f0fhqFXG"
      },
      "source": [
        "def train():\n",
        "  \n",
        "  model.train()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save model predictions\n",
        "  total_preds=[]\n",
        "  \n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    \n",
        "    # progress update after every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [r.cpu().to(device) for r in batch]\n",
        " \n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # clear previously calculated gradients \n",
        "    model.zero_grad()        \n",
        "\n",
        "    # get model predictions for the current batch\n",
        "    preds = model(sent_id, mask)\n",
        "\n",
        "    # compute the loss between actual and predicted values\n",
        "    loss = cross_entropy(preds, labels)\n",
        "\n",
        "    # add on to the total loss\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "    # backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # model predictions are stored on GPU. So, push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  # compute the training loss of the epoch\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "  \n",
        "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  #returns the loss and predictions\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmFTI2PVqJZL"
      },
      "source": [
        "def evaluate():\n",
        "  \n",
        "  print(\"\\nEvaluating...\")\n",
        "  \n",
        "  # deactivate dropout layers\n",
        "  model.eval()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(val_dataloader):\n",
        "    \n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      \n",
        "            \n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [t.to(device) for t in batch]\n",
        "\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # deactivate autograd\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      # model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "\n",
        "      # compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels)\n",
        "\n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  # compute the validation loss of the epoch\n",
        "  avg_loss = total_loss / len(val_dataloader) \n",
        "\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWpVwR9-qN-K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c509e7d2-7e57-4ccf-9be1-d499a6fb17f2"
      },
      "source": [
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    \n",
        "    #train model\n",
        "    train_loss, temp = train()\n",
        "    \n",
        "    #evaluate model\n",
        "    valid_loss, temp = evaluate()\n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 10\n",
            "  Batch    50  of    788.\n",
            "  Batch   100  of    788.\n",
            "  Batch   150  of    788.\n",
            "  Batch   200  of    788.\n",
            "  Batch   250  of    788.\n",
            "  Batch   300  of    788.\n",
            "  Batch   350  of    788.\n",
            "  Batch   400  of    788.\n",
            "  Batch   450  of    788.\n",
            "  Batch   500  of    788.\n",
            "  Batch   550  of    788.\n",
            "  Batch   600  of    788.\n",
            "  Batch   650  of    788.\n",
            "  Batch   700  of    788.\n",
            "  Batch   750  of    788.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    169.\n",
            "  Batch   100  of    169.\n",
            "  Batch   150  of    169.\n",
            "\n",
            "Training Loss: 1.296\n",
            "Validation Loss: 0.847\n",
            "\n",
            " Epoch 2 / 10\n",
            "  Batch    50  of    788.\n",
            "  Batch   100  of    788.\n",
            "  Batch   150  of    788.\n",
            "  Batch   200  of    788.\n",
            "  Batch   250  of    788.\n",
            "  Batch   300  of    788.\n",
            "  Batch   350  of    788.\n",
            "  Batch   400  of    788.\n",
            "  Batch   450  of    788.\n",
            "  Batch   500  of    788.\n",
            "  Batch   550  of    788.\n",
            "  Batch   600  of    788.\n",
            "  Batch   650  of    788.\n",
            "  Batch   700  of    788.\n",
            "  Batch   750  of    788.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    169.\n",
            "  Batch   100  of    169.\n",
            "  Batch   150  of    169.\n",
            "\n",
            "Training Loss: 0.637\n",
            "Validation Loss: 0.614\n",
            "\n",
            " Epoch 3 / 10\n",
            "  Batch    50  of    788.\n",
            "  Batch   100  of    788.\n",
            "  Batch   150  of    788.\n",
            "  Batch   200  of    788.\n",
            "  Batch   250  of    788.\n",
            "  Batch   300  of    788.\n",
            "  Batch   350  of    788.\n",
            "  Batch   400  of    788.\n",
            "  Batch   450  of    788.\n",
            "  Batch   500  of    788.\n",
            "  Batch   550  of    788.\n",
            "  Batch   600  of    788.\n",
            "  Batch   650  of    788.\n",
            "  Batch   700  of    788.\n",
            "  Batch   750  of    788.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    169.\n",
            "  Batch   100  of    169.\n",
            "  Batch   150  of    169.\n",
            "\n",
            "Training Loss: 0.405\n",
            "Validation Loss: 0.583\n",
            "\n",
            " Epoch 4 / 10\n",
            "  Batch    50  of    788.\n",
            "  Batch   100  of    788.\n",
            "  Batch   150  of    788.\n",
            "  Batch   200  of    788.\n",
            "  Batch   250  of    788.\n",
            "  Batch   300  of    788.\n",
            "  Batch   350  of    788.\n",
            "  Batch   400  of    788.\n",
            "  Batch   450  of    788.\n",
            "  Batch   500  of    788.\n",
            "  Batch   550  of    788.\n",
            "  Batch   600  of    788.\n",
            "  Batch   650  of    788.\n",
            "  Batch   700  of    788.\n",
            "  Batch   750  of    788.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    169.\n",
            "  Batch   100  of    169.\n",
            "  Batch   150  of    169.\n",
            "\n",
            "Training Loss: 0.284\n",
            "Validation Loss: 0.585\n",
            "\n",
            " Epoch 5 / 10\n",
            "  Batch    50  of    788.\n",
            "  Batch   100  of    788.\n",
            "  Batch   150  of    788.\n",
            "  Batch   200  of    788.\n",
            "  Batch   250  of    788.\n",
            "  Batch   300  of    788.\n",
            "  Batch   350  of    788.\n",
            "  Batch   400  of    788.\n",
            "  Batch   450  of    788.\n",
            "  Batch   500  of    788.\n",
            "  Batch   550  of    788.\n",
            "  Batch   600  of    788.\n",
            "  Batch   650  of    788.\n",
            "  Batch   700  of    788.\n",
            "  Batch   750  of    788.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    169.\n",
            "  Batch   100  of    169.\n",
            "  Batch   150  of    169.\n",
            "\n",
            "Training Loss: 0.229\n",
            "Validation Loss: 0.582\n",
            "\n",
            " Epoch 6 / 10\n",
            "  Batch    50  of    788.\n",
            "  Batch   100  of    788.\n",
            "  Batch   150  of    788.\n",
            "  Batch   200  of    788.\n",
            "  Batch   250  of    788.\n",
            "  Batch   300  of    788.\n",
            "  Batch   350  of    788.\n",
            "  Batch   400  of    788.\n",
            "  Batch   450  of    788.\n",
            "  Batch   500  of    788.\n",
            "  Batch   550  of    788.\n",
            "  Batch   600  of    788.\n",
            "  Batch   650  of    788.\n",
            "  Batch   700  of    788.\n",
            "  Batch   750  of    788.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    169.\n",
            "  Batch   100  of    169.\n",
            "  Batch   150  of    169.\n",
            "\n",
            "Training Loss: 0.185\n",
            "Validation Loss: 0.617\n",
            "\n",
            " Epoch 7 / 10\n",
            "  Batch    50  of    788.\n",
            "  Batch   100  of    788.\n",
            "  Batch   150  of    788.\n",
            "  Batch   200  of    788.\n",
            "  Batch   250  of    788.\n",
            "  Batch   300  of    788.\n",
            "  Batch   350  of    788.\n",
            "  Batch   400  of    788.\n",
            "  Batch   450  of    788.\n",
            "  Batch   500  of    788.\n",
            "  Batch   550  of    788.\n",
            "  Batch   600  of    788.\n",
            "  Batch   650  of    788.\n",
            "  Batch   700  of    788.\n",
            "  Batch   750  of    788.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    169.\n",
            "  Batch   100  of    169.\n",
            "  Batch   150  of    169.\n",
            "\n",
            "Training Loss: 0.165\n",
            "Validation Loss: 0.700\n",
            "\n",
            " Epoch 8 / 10\n",
            "  Batch    50  of    788.\n",
            "  Batch   100  of    788.\n",
            "  Batch   150  of    788.\n",
            "  Batch   200  of    788.\n",
            "  Batch   250  of    788.\n",
            "  Batch   300  of    788.\n",
            "  Batch   350  of    788.\n",
            "  Batch   400  of    788.\n",
            "  Batch   450  of    788.\n",
            "  Batch   500  of    788.\n",
            "  Batch   550  of    788.\n",
            "  Batch   600  of    788.\n",
            "  Batch   650  of    788.\n",
            "  Batch   700  of    788.\n",
            "  Batch   750  of    788.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    169.\n",
            "  Batch   100  of    169.\n",
            "  Batch   150  of    169.\n",
            "\n",
            "Training Loss: 0.146\n",
            "Validation Loss: 0.708\n",
            "\n",
            " Epoch 9 / 10\n",
            "  Batch    50  of    788.\n",
            "  Batch   100  of    788.\n",
            "  Batch   150  of    788.\n",
            "  Batch   200  of    788.\n",
            "  Batch   250  of    788.\n",
            "  Batch   300  of    788.\n",
            "  Batch   350  of    788.\n",
            "  Batch   400  of    788.\n",
            "  Batch   450  of    788.\n",
            "  Batch   500  of    788.\n",
            "  Batch   550  of    788.\n",
            "  Batch   600  of    788.\n",
            "  Batch   650  of    788.\n",
            "  Batch   700  of    788.\n",
            "  Batch   750  of    788.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    169.\n",
            "  Batch   100  of    169.\n",
            "  Batch   150  of    169.\n",
            "\n",
            "Training Loss: 0.138\n",
            "Validation Loss: 0.768\n",
            "\n",
            " Epoch 10 / 10\n",
            "  Batch    50  of    788.\n",
            "  Batch   100  of    788.\n",
            "  Batch   150  of    788.\n",
            "  Batch   200  of    788.\n",
            "  Batch   250  of    788.\n",
            "  Batch   300  of    788.\n",
            "  Batch   350  of    788.\n",
            "  Batch   400  of    788.\n",
            "  Batch   450  of    788.\n",
            "  Batch   500  of    788.\n",
            "  Batch   550  of    788.\n",
            "  Batch   600  of    788.\n",
            "  Batch   650  of    788.\n",
            "  Batch   700  of    788.\n",
            "  Batch   750  of    788.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    169.\n",
            "  Batch   100  of    169.\n",
            "  Batch   150  of    169.\n",
            "\n",
            "Training Loss: 0.132\n",
            "Validation Loss: 0.839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ky9UyM67vfeg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acb252d0-927d-44a6-a9b9-f66450f0a861"
      },
      "source": [
        "path = 'saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC_ub534y5d_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f36abef5-5fd3-4bd5-f906-847f1d0729f2"
      },
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "139"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeRmGQMXAIx9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "18691179-ad20-446e-fab9-37cb2fe3d875"
      },
      "source": [
        "with torch.no_grad():\n",
        "  preds = model(test_seq.to(device), test_mask.to(device))\n",
        "  preds = preds.detach().cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-dc426d657c77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-f2e45a5f523e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sent_id, mask)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m       \u001b[0;31m#pass the inputs to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_hs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_hs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    998\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1000\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1001\u001b[0m         )\n\u001b[1;32m   1002\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    587\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m                 )\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         layer_output = apply_chunking_to_forward(\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m         )\n\u001b[1;32m    513\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   2194\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2196\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mgelu\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m   1553\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_unary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgelu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1555\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 3.09 GiB (GPU 0; 11.17 GiB total capacity; 7.88 GiB already allocated; 1.15 GiB free; 9.56 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-KZwElwAJG-"
      },
      "source": [
        "preds = np.argmax(preds, axis = 1)\n",
        "print(classification_report(test_y, preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYLj0-uAAOXv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}